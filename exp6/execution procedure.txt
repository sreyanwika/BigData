
1.create java project and save with appropriate project name 

2.Right click on project and create 3 java class (Mainfile, Mapper, Reducer)

3.Add Jar files-right click on project , 
a.choose build path option 
b.choose configure build path 
c.click on add external jars
d.path - Desktop/hadoop-java-jars - select all by pressing ctrl A , click ok 

4.Add implementation code in all three java files 

 ---> Create jar file (right click proj name, export, jar creation)

5.commands for execution - open new terminal 

6.hadoop dfs -mkdir /input - create directory to store all dataset files in HDFS- 
  hadoop dfs -mkdir /wc

  hadoop dfs -ls /input    -displays files inside input directory
  hadoop dfs -ls /wc

7.hadoop dfs -put local file system path /input/  - copies file from local file system to HDFS 
               put /home/training/Desktop/wcinput /wc

8.hadoop jar path-to-jarfile mainclass /path-to-inputfile /output

copy paste path wherever required 
hadoop jar /home/training/Desktop/wc.jar wordcount /wc/wcinput /wcout3 


9.to check output there are 2 ways :

a.check output from browser --- open firefox browser type in url 
  localhost:50070- browse filesystem choose output directory and open part-00000 file 

b.use cat command

   hadoop dfs -ls /output --displays contents of output directory   
   hadoop dfs -cat /output/part-00000 - displays contents of this file 


Hint: In main Class change 

class name in JobConf() function 
class name in setMapperClass() function
class name in setreducerClass() function 
main method change in run() with constructor name 
 


